{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UTJmsXnXQKbG"
   },
   "source": [
    "## Keras -- MLPs on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2UILABPAQKbH"
   },
   "outputs": [],
   "source": [
    "# if you keras is not using tensorflow as backend set \"KERAS_BACKEND=tensorflow\" use this command\n",
    "from keras.utils import np_utils \n",
    "from keras.datasets import mnist\n",
    "import seaborn as sns\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOO-TM_7QKbM"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
    "# https://stackoverflow.com/a/14434334\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, colors=['b']):\n",
    "    plt.plot(x, vy, color = 'b', label='Validation Loss')\n",
    "    plt.plot(x, ty, color = 'r', label='Train Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Categorical Crossentropy Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4008,
     "status": "ok",
     "timestamp": 1584021436683,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "TKmYKnibQKbQ",
    "outputId": "dd3bf0c8-82d0-44df-adae-0f20845a9a0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1378,
     "status": "ok",
     "timestamp": 1584021442982,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "CCwnZae-QKbT",
    "outputId": "56b5bd86-aa26-41f7-de96-9542eb6f90c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples : 60000 and each image is of shape (28, 28)\n",
      "Number of training examples : 10000 and each image is of shape (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d, %d)\"%(X_train.shape[1], X_train.shape[2]))\n",
    "print(\"Number of training examples :\", X_test.shape[0], \"and each image is of shape (%d, %d)\"%(X_test.shape[1], X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BlotuCmoQKbW"
   },
   "outputs": [],
   "source": [
    "# if you observe the input shape its 2 dimensional vector\n",
    "# for each image we have a (28*28) vector\n",
    "# we will convert the (28*28) vector into single dimensional vector of 1 * 784 \n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]) \n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1357,
     "status": "ok",
     "timestamp": 1584021529706,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "8JvpNJy4QKbY",
    "outputId": "a57f90d0-1ffe-4e62-e6bf-a4bc2ed0ddca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples : 60000 and each image is of shape (784)\n",
      "Number of training examples : 10000 and each image is of shape (784)\n"
     ]
    }
   ],
   "source": [
    "# after converting the input images from 3d to 2d vectors\n",
    "\n",
    "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d)\"%(X_train.shape[1]))\n",
    "print(\"Number of training examples :\", X_test.shape[0], \"and each image is of shape (%d)\"%(X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1389,
     "status": "ok",
     "timestamp": 1584021533380,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "qvuaHDk0QKbb",
    "outputId": "98bf9087-c91d-4b63-8449-d0dc51f8abd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# An example data point\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfohtdKPQKbd"
   },
   "outputs": [],
   "source": [
    "# if we observe the above matrix each cell is having a value between 0-255\n",
    "# before we move to apply machine learning algorithms lets try to normalize the data\n",
    "# X => (X - Xmin)/(Xmax-Xmin) = X/255\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1254,
     "status": "ok",
     "timestamp": 1584021539394,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "4C-dmsXJQKbf",
    "outputId": "91a3aa72-42bc-428e-8511-065599f9ec3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215686\n",
      " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
      " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313725\n",
      " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1372549  0.94509804\n",
      " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      " 0.58823529 0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.58039216\n",
      " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058824\n",
      " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
      " 0.31372549 0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333333 0.99215686\n",
      " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# example data point after normlizing\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1260,
     "status": "ok",
     "timestamp": 1584021544704,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "3Ruu-vXzQKbi",
    "outputId": "ae69f924-6321-4194-bc19-b23bc815f9ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label of first image : 5\n",
      "After converting the output into a vector :  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# here we are having a class number for each image\n",
    "print(\"Class label of first image :\", y_train[0])\n",
    "\n",
    "# lets convert this into a 10 dimensional vector\n",
    "# ex: consider an image is 5 convert it into 5 => [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "# this conversion needed for MLPs \n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 10) \n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"After converting the output into a vector : \",Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0pWB6UyQKbk"
   },
   "source": [
    "<h2>  Softmax classifier  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLAGMubCQKbm"
   },
   "outputs": [],
   "source": [
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "# The Sequential model is a linear stack of layers.\n",
    "# you can create a Sequential model by passing a list of layer instances to the constructor:\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(32, input_shape=(784,)),\n",
    "#     Activation('relu'),\n",
    "#     Dense(10),\n",
    "#     Activation('softmax'),\n",
    "# ])\n",
    "\n",
    "# You can also simply add layers via the .add() method:\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, input_dim=784))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "###\n",
    "\n",
    "# https://keras.io/layers/core/\n",
    "\n",
    "# keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', \n",
    "# bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
    "# kernel_constraint=None, bias_constraint=None)\n",
    "\n",
    "# Dense implements the operation: output = activation(dot(input, kernel) + bias) where\n",
    "# activation is the element-wise activation function passed as the activation argument, \n",
    "# kernel is a weights matrix created by the layer, and \n",
    "# bias is a bias vector created by the layer (only applicable if use_bias is True).\n",
    "\n",
    "# output = activation(dot(input, kernel) + bias)  => y = activation(WT. X + b)\n",
    "\n",
    "####\n",
    "\n",
    "# https://keras.io/activations/\n",
    "\n",
    "# Activations can either be used through an Activation layer, or through the activation argument supported by all forward layers:\n",
    "\n",
    "# from keras.layers import Activation, Dense\n",
    "\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('tanh'))\n",
    "\n",
    "# This is equivalent to:\n",
    "# model.add(Dense(64, activation='tanh'))\n",
    "\n",
    "# there are many activation functions ar available ex: tanh, relu, softmax\n",
    "\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization, Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0s7jzhVQKbn"
   },
   "outputs": [],
   "source": [
    "# some model parameters\n",
    "\n",
    "output_dim = 10\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "batch_size = 128 \n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHh06094EowI"
   },
   "source": [
    "# 1. two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1297,
     "status": "ok",
     "timestamp": 1584022002067,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "HdQg5wGDQKbr",
    "outputId": "e1d42b6b-8e72-45f0-8924-00eeca8da6e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# start building a model\n",
    "model = Sequential()\n",
    "\n",
    "# The model needs to know what input shape it should expect. \n",
    "# For this reason, the first layer in a Sequential model \n",
    "# (and only the first, because following layers can do automatic shape inference)\n",
    "# needs to receive information about its input shape. \n",
    "# you can use input_shape and input_dim to pass the shape of input\n",
    "\n",
    "# output_dim represent the number of nodes need in that layer\n",
    "# here we have 10 nodes\n",
    "\n",
    "model.add(Dense(units=256, input_shape=(input_dim,), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(output_dim, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1326,
     "status": "ok",
     "timestamp": 1584022189431,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "qWwiIGyGFF0p",
    "outputId": "a0b566ad-15f5-4515-a200-e90591ae542e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,658\n",
      "Trainable params: 235,402\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 88477,
     "status": "ok",
     "timestamp": 1584022113756,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "EVA11VpmQKbt",
    "outputId": "acc25e4c-3818-4ef1-a5bf-ed9301b8299f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.2877 - acc: 0.9166 - val_loss: 0.1143 - val_acc: 0.9649\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1233 - acc: 0.9627 - val_loss: 0.0876 - val_acc: 0.9733\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0895 - acc: 0.9723 - val_loss: 0.0763 - val_acc: 0.9774\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0726 - acc: 0.9771 - val_loss: 0.0655 - val_acc: 0.9796\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0631 - acc: 0.9797 - val_loss: 0.0640 - val_acc: 0.9802\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0536 - acc: 0.9831 - val_loss: 0.0668 - val_acc: 0.9797\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0470 - acc: 0.9845 - val_loss: 0.0676 - val_acc: 0.9798\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0454 - acc: 0.9854 - val_loss: 0.0634 - val_acc: 0.9798\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0395 - acc: 0.9870 - val_loss: 0.0683 - val_acc: 0.9790\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0393 - acc: 0.9868 - val_loss: 0.0569 - val_acc: 0.9826\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0311 - acc: 0.9894 - val_loss: 0.0608 - val_acc: 0.9811\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0309 - acc: 0.9894 - val_loss: 0.0626 - val_acc: 0.9826\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0283 - acc: 0.9902 - val_loss: 0.0618 - val_acc: 0.9818\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0274 - acc: 0.9903 - val_loss: 0.0610 - val_acc: 0.9811\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0273 - acc: 0.9907 - val_loss: 0.0597 - val_acc: 0.9826\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0250 - acc: 0.9916 - val_loss: 0.0637 - val_acc: 0.9823\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0237 - acc: 0.9915 - val_loss: 0.0576 - val_acc: 0.9833\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0219 - acc: 0.9925 - val_loss: 0.0646 - val_acc: 0.9830\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0206 - acc: 0.9929 - val_loss: 0.0611 - val_acc: 0.9822\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0229 - acc: 0.9921 - val_loss: 0.0633 - val_acc: 0.9821\n"
     ]
    }
   ],
   "source": [
    "# Before training a model, you need to configure the learning process, which is done via the compile method\n",
    "\n",
    "# It receives three arguments:\n",
    "# An optimizer. This could be the string identifier of an existing optimizer , https://keras.io/optimizers/\n",
    "# A loss function. This is the objective that the model will try to minimize., https://keras.io/losses/\n",
    "# A list of metrics. For any classification problem you will want to set this to metrics=['accuracy'].  https://keras.io/metrics/\n",
    "\n",
    "\n",
    "# Note: when using the categorical_crossentropy loss, your targets should be in categorical format \n",
    "# (e.g. if you have 10 classes, the target for each sample should be a 10-dimensional vector that is all-zeros except \n",
    "# for a 1 at the index corresponding to the class of the sample).\n",
    "\n",
    "# that is why we converted out labels into vectors\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Keras models are trained on Numpy arrays of input data and labels. \n",
    "# For training a model, you will typically use the  fit function\n",
    "\n",
    "# fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, \n",
    "# validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, \n",
    "# validation_steps=None)\n",
    "\n",
    "# fit() function Trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "\n",
    "# it returns A History object. Its History.history attribute is a record of training loss values and \n",
    "# metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).\n",
    "\n",
    "# https://github.com/openai/baselines/issues/20\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1707,
     "status": "ok",
     "timestamp": 1584023283122,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "HNpwTMHcQKbw",
    "outputId": "90675e4c-0414-46c5-cb1e-737bdc175bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.063285964876238\n",
      "Test accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1584023288034,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "DvixYVLaGVik",
    "outputId": "4ee32122-8685-4354-f681-5fe21fe1edd8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_dynamic(x, vy, ty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eh4VWYrHQKbz"
   },
   "source": [
    "#2. three hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rzbngqHQKbz"
   },
   "outputs": [],
   "source": [
    "# start building a model\n",
    "model = Sequential()\n",
    "\n",
    "# The model needs to know what input shape it should expect. \n",
    "# For this reason, the first layer in a Sequential model \n",
    "# (and only the first, because following layers can do automatic shape inference)\n",
    "# needs to receive information about its input shape. \n",
    "# you can use input_shape and input_dim to pass the shape of input\n",
    "\n",
    "# output_dim represent the number of nodes need in that layer\n",
    "# here we have 10 nodes\n",
    "\n",
    "model.add(Dense(units=256, input_shape=(input_dim,), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(output_dim, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1295,
     "status": "ok",
     "timestamp": 1584023361911,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "9QhloE56JkIq",
    "outputId": "f39b9be9-2baf-4ed4-f2c7-9d6d8451cd5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 301,450\n",
      "Trainable params: 301,194\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 88210,
     "status": "ok",
     "timestamp": 1584023469218,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "48vVImSpQKb5",
    "outputId": "dc92ef1b-421c-4976-fd4c-fbf53298611b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.3157 - acc: 0.9054 - val_loss: 0.1099 - val_acc: 0.9668\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1349 - acc: 0.9589 - val_loss: 0.0921 - val_acc: 0.9710\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1037 - acc: 0.9682 - val_loss: 0.0806 - val_acc: 0.9756\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0863 - acc: 0.9732 - val_loss: 0.0690 - val_acc: 0.9798\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0741 - acc: 0.9765 - val_loss: 0.0660 - val_acc: 0.9807\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0650 - acc: 0.9792 - val_loss: 0.0669 - val_acc: 0.9801\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0567 - acc: 0.9817 - val_loss: 0.0671 - val_acc: 0.9807\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0533 - acc: 0.9826 - val_loss: 0.0682 - val_acc: 0.9808\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0489 - acc: 0.9838 - val_loss: 0.0673 - val_acc: 0.9811\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0440 - acc: 0.9864 - val_loss: 0.0680 - val_acc: 0.9807\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0422 - acc: 0.9864 - val_loss: 0.0669 - val_acc: 0.9813\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0398 - acc: 0.9870 - val_loss: 0.0680 - val_acc: 0.9820\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0363 - acc: 0.9883 - val_loss: 0.0602 - val_acc: 0.9836\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0322 - acc: 0.9890 - val_loss: 0.0620 - val_acc: 0.9831\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0344 - acc: 0.9882 - val_loss: 0.0583 - val_acc: 0.9817\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0303 - acc: 0.9899 - val_loss: 0.0648 - val_acc: 0.9828\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0299 - acc: 0.9900 - val_loss: 0.0686 - val_acc: 0.9819\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0286 - acc: 0.9904 - val_loss: 0.0619 - val_acc: 0.9829\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0266 - acc: 0.9913 - val_loss: 0.0627 - val_acc: 0.9835\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0270 - acc: 0.9912 - val_loss: 0.0567 - val_acc: 0.9850\n"
     ]
    }
   ],
   "source": [
    "# Before training a model, you need to configure the learning process, which is done via the compile method\n",
    "\n",
    "# It receives three arguments:\n",
    "# An optimizer. This could be the string identifier of an existing optimizer , https://keras.io/optimizers/\n",
    "# A loss function. This is the objective that the model will try to minimize., https://keras.io/losses/\n",
    "# A list of metrics. For any classification problem you will want to set this to metrics=['accuracy'].  https://keras.io/metrics/\n",
    "\n",
    "\n",
    "# Note: when using the categorical_crossentropy loss, your targets should be in categorical format \n",
    "# (e.g. if you have 10 classes, the target for each sample should be a 10-dimensional vector that is all-zeros except \n",
    "# for a 1 at the index corresponding to the class of the sample).\n",
    "\n",
    "# that is why we converted out labels into vectors\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Keras models are trained on Numpy arrays of input data and labels. \n",
    "# For training a model, you will typically use the  fit function\n",
    "\n",
    "# fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, \n",
    "# validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, \n",
    "# validation_steps=None)\n",
    "\n",
    "# fit() function Trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "\n",
    "# it returns A History object. Its History.history attribute is a record of training loss values and \n",
    "# metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).\n",
    "\n",
    "# https://github.com/openai/baselines/issues/20\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1724,
     "status": "ok",
     "timestamp": 1584023492083,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "6ffjzr8hQKb8",
    "outputId": "76ef5d36-7606-4fdd-a645-9006b98bdd76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.05666124046119221\n",
      "Test accuracy: 0.985\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1324,
     "status": "ok",
     "timestamp": 1584023495637,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "VDohz82GJ9lC",
    "outputId": "7c78f3cc-7d83-400e-a5f0-e61f71e007a8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxGQJwhhjTEyWIIwxxsRkCcIYY0xM/x/fEnZZM/qLTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_dynamic(x, vy, ty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. five hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QEAaMAUWKF5V"
   },
   "outputs": [],
   "source": [
    "# start building a model\n",
    "model = Sequential()\n",
    "\n",
    "# The model needs to know what input shape it should expect. \n",
    "# For this reason, the first layer in a Sequential model \n",
    "# (and only the first, because following layers can do automatic shape inference)\n",
    "# needs to receive information about its input shape. \n",
    "# you can use input_shape and input_dim to pass the shape of input\n",
    "\n",
    "# output_dim represent the number of nodes need in that layer\n",
    "# here we have 10 nodes\n",
    "\n",
    "model.add(Dense(units=256, input_shape=(input_dim,), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(output_dim, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1704,
     "status": "ok",
     "timestamp": 1584024071708,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "KxfbwZ5RKXO0",
    "outputId": "155295a9-020e-498c-deed-f614cf46eaa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 564,362\n",
      "Trainable params: 564,106\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 104993,
     "status": "ok",
     "timestamp": 1584024177326,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "Qh9HihvWKZdM",
    "outputId": "96aed32a-e044-4e75-941f-631de0e15ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.4301 - acc: 0.8676 - val_loss: 0.1490 - val_acc: 0.9553\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1758 - acc: 0.9497 - val_loss: 0.1054 - val_acc: 0.9684\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1336 - acc: 0.9618 - val_loss: 0.0877 - val_acc: 0.9751\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1079 - acc: 0.9682 - val_loss: 0.0876 - val_acc: 0.9758\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0968 - acc: 0.9719 - val_loss: 0.0837 - val_acc: 0.9764\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0852 - acc: 0.9759 - val_loss: 0.0800 - val_acc: 0.9777\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0804 - acc: 0.9762 - val_loss: 0.0677 - val_acc: 0.9805\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0717 - acc: 0.9795 - val_loss: 0.0703 - val_acc: 0.9804\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0652 - acc: 0.9808 - val_loss: 0.0771 - val_acc: 0.9790\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0639 - acc: 0.9817 - val_loss: 0.0739 - val_acc: 0.9799\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0552 - acc: 0.9834 - val_loss: 0.0820 - val_acc: 0.9794\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0530 - acc: 0.9847 - val_loss: 0.0704 - val_acc: 0.9801\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0513 - acc: 0.9850 - val_loss: 0.0687 - val_acc: 0.9817\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0450 - acc: 0.9866 - val_loss: 0.0743 - val_acc: 0.9808\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0464 - acc: 0.9861 - val_loss: 0.0696 - val_acc: 0.9816\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0464 - acc: 0.9862 - val_loss: 0.0671 - val_acc: 0.9831\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0391 - acc: 0.9888 - val_loss: 0.0779 - val_acc: 0.9796\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0399 - acc: 0.9878 - val_loss: 0.0690 - val_acc: 0.9835\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0390 - acc: 0.9882 - val_loss: 0.0624 - val_acc: 0.9841\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0326 - acc: 0.9904 - val_loss: 0.0728 - val_acc: 0.9827\n"
     ]
    }
   ],
   "source": [
    "# Before training a model, you need to configure the learning process, which is done via the compile method\n",
    "\n",
    "# It receives three arguments:\n",
    "# An optimizer. This could be the string identifier of an existing optimizer , https://keras.io/optimizers/\n",
    "# A loss function. This is the objective that the model will try to minimize., https://keras.io/losses/\n",
    "# A list of metrics. For any classification problem you will want to set this to metrics=['accuracy'].  https://keras.io/metrics/\n",
    "\n",
    "\n",
    "# Note: when using the categorical_crossentropy loss, your targets should be in categorical format \n",
    "# (e.g. if you have 10 classes, the target for each sample should be a 10-dimensional vector that is all-zeros except \n",
    "# for a 1 at the index corresponding to the class of the sample).\n",
    "\n",
    "# that is why we converted out labels into vectors\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Keras models are trained on Numpy arrays of input data and labels. \n",
    "# For training a model, you will typically use the  fit function\n",
    "\n",
    "# fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, \n",
    "# validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, \n",
    "# validation_steps=None)\n",
    "\n",
    "# fit() function Trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "\n",
    "# it returns A History object. Its History.history attribute is a record of training loss values and \n",
    "# metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).\n",
    "\n",
    "# https://github.com/openai/baselines/issues/20\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 103246,
     "status": "ok",
     "timestamp": 1584024177745,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "UCf8m8zkKgEq",
    "outputId": "3b8cce43-d3df-4c3c-d7f7-7110847c1451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.07284883902525763\n",
      "Test accuracy: 0.9827\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 102429,
     "status": "ok",
     "timestamp": 1584024178281,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "F7FooXw_KlrO",
    "outputId": "36a983e2-ca14-4d47-dc95-d672a397b504"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_dynamic(x, vy, ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jgtz7CMK7c4"
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vL1hsNptLIxP"
   },
   "outputs": [],
   "source": [
    "x = PrettyTable()\n",
    "x.field_names = [\"#layers\", \"Train Loss/Acc\",\"Test Loss/Acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRgokjaVLj3Z"
   },
   "outputs": [],
   "source": [
    "x.add_row(['2 layers (256(p=25%),128(BN))','2.3% / 99.21%','6.3% / 98.21%'])\n",
    "x.add_row(['3 layers (256(p=25%),256(p=25%),128(BN))','2.7% / 99.12%','5.7% / 98.5%'])\n",
    "x.add_row(['5 layers (256(p=25%),256(p=25%),512(p=50%),256(p=25%),128(BN))','3.3% / 99.04%','7.3% / 98.27%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3887,
     "status": "ok",
     "timestamp": 1584024633415,
     "user": {
      "displayName": "Sahil -",
      "photoUrl": "",
      "userId": "14051148522636395588"
     },
     "user_tz": -330
    },
    "id": "k0IvEMeyNVWY",
    "outputId": "77752c79-ba65-4f06-90ec-80833f8c2bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------+----------------+---------------+\n",
      "|                            #layers                             | Train Loss/Acc | Test Loss/Acc |\n",
      "+----------------------------------------------------------------+----------------+---------------+\n",
      "|                 2 layers (256(p=25%),128(BN))                  | 2.3% / 99.21%  | 6.3% / 98.21% |\n",
      "|            3 layers (256(p=25%),256(p=25%),128(BN))            | 2.7% / 99.12%  |  5.7% / 98.5% |\n",
      "| 5 layers (256(p=25%),256(p=25%),512(p=50%),256(p=25%),128(BN)) | 3.3% / 99.04%  | 7.3% / 98.27% |\n",
      "+----------------------------------------------------------------+----------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MAxxnKANadW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keras_Mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
